#### Perspective
I thought the last commit would be enough to make me start actually using the project (i.e. by starting to do some mapping).
I stumbled across the perspective problem far too early:
in the abstract I stated that "perspective" is/will be a problem with this project, but as I started drawing my first 2 concepts I immediately made 2 conclusions:

1. I was right about the paradox of the concept map losing value as we change perspective
2. I didn't want to be right.
3. Space needs to be reinvented

More in detail, I wanted to map many concepts about artificial intelligence. Then I wanted to draw a concept A about "What's my cognition about artificial intelligence"
How exactly should I connect A to? 
There isn't a concept called "AI" because it's made of all the different concepts I previously made. 

Anyways: that's the least of the problems. 
Because, guess what, there actually *is* a paradox.

imagine this situation:

<img src="https://github.com/dennisorlando/lifemap/blob/main/map0.png" width=50% height=50%>

....as you can see, the big red line connecting "dog" and "humans" is not exaclty... ideal. Imagine having to deal with hundreds of those. 
But I'm not sure *what* exactly is the problem. What's the difference between what I have drawn and what I actually want to draw?

In the map, dogs and humands are apart even if in my mind they are close to each other. 
If we reverse this fact, we might be able to agree that in cognition there's hardly anything to refer to as "distance between concepts", if not a biological distance
between neurons representing those concepts but that's negligible for this project.
If my intuition is still working (it's 11pm) then I might say that this is a paradox, because when we draw a map we end up drawing concepts in a 2d space, each of
them with a fixed position and an actual "size".
This should be the reason why we encounter problems like the one I've shown you with dogs and humans:
connected concepts end up far from eachother because of the physical restraints of associating a 2d space with the map. 

The solution would most certainly be to add other dimensions. This is known to be working for natural language processing: each word token is represented by a
n-dimensional vector in an n-dimensional space.
Yet this is not a solution for us because humans can't represent something they do not understand; I'm obviously talking about the fact that visualizing
and adding concepts in an n-dimensional array is practically impossible. 
